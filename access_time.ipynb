{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-defense",
   "metadata": {},
   "source": [
    "# Accessibility for Competing Destintion models\n",
    "\n",
    "I needed to replicate the CD model for my research and found out no function that would help me to estimate the accessibility term exist yet.\n",
    "\n",
    "Here I am trying to build this function, in different ways, compare their computational time, and see if I can speed it up to accomodate a big data.\n",
    "\n",
    "## Accessibility term\n",
    "\n",
    "$A_{ij}$ represents the accessibility of destination $j$ to all other destinations available to origin $i$ as perceived by the\n",
    "residents of origin $i$ and is defined as\n",
    "\n",
    "![png](./acc1.png)\n",
    "\n",
    "This can be little confusing, so let's break it down.\n",
    "\n",
    "Imagine a migration between 5 following English cities, where pople from Liverpool migrate to South Hampton, Bristol and London, and from London to Brighton.\n",
    "We want to calculate the accessibility term for the flow Liverpool to Bristol.\n",
    "\n",
    "Here the accessibility of $\\text{flow}_{Li,B}$ is the sum of the connections between the destination (Bristol) to all other destinations. This connection or accessibility between Bristol and other destinations can be then calculated as the distance between Bristol and destination times the mass of the destination. \n",
    "\n",
    "![png](./Graph_acc.png)\n",
    "\n",
    "In other words;\n",
    "\n",
    "$$  \\text{Accessibility for the flow between Liverpool and Bristol} = \\sum \\text{population SH * distance1, population Lo * distance2} $$\n",
    "                                                                                 \n",
    "                                                                                 \n",
    "**Important**: We don't necesserily know if this is ment as an accesibility of all possible destinations in a system, or only those that actually exist for given origin. \n",
    "\n",
    "I design 2 functions\n",
    "\n",
    "    1. AFAP = Accessibility of flow taking all possible destinations in the system \n",
    "    2. AFOE = Accessibility of flow taking only existing destinations\n",
    "\n",
    "In those two function, we will assume that the inputs are 3 data frames matching each other\n",
    "    * DF of flows combination\n",
    "    * DF of all possible flows in system and distances between them\n",
    "    * DF of all points with their masses\n",
    "    \n",
    "![png](./table1.png)\n",
    "    \n",
    "Additionally, I have refined those into 1 function only, that can handle both situations and is presumably quicker (will see abouyt that).\n",
    "This I function takes one Data Frame of all possible flow combinations, their distances, weight on the flow (this indicates if flow exists or not) and destination masses\n",
    "\n",
    "    3. AFED = Accessibility of flow taking existing destinations\n",
    "\n",
    "![png](./table2.png)\n",
    "    \n",
    "## Define the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "athletic-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. AFAP = Accessibility of flow taking all possible destinations in the system \n",
    "\n",
    "def AFAP(distances_df, dest_masses_df, flow_df, row_index): # AFAPF\n",
    "    # rename teh columns so we can call them \n",
    "    distances_df = distances_df.rename(columns = {distances_df.columns[0]:'origin_ID', distances_df.columns[1]:'dest_ID', distances_df.columns[2]:'weight'})\n",
    "    dest_masses_df = dest_masses_df.rename(columns = {dest_masses_df.columns[0]:'ID', dest_masses_df.columns[1]:'mass'})\n",
    "    flow_df = flow_df.rename(columns = {flow_df.columns[0]:'origin_ID', flow_df.columns[1]:'dest_ID'})\n",
    "    \n",
    "    # define the variables\n",
    "    all_dest = flow_df['dest_ID'].unique()\n",
    "    D = flow_df['dest_ID'][row_index]\n",
    "    O = flow_df['origin_ID'][row_index]\n",
    "    \n",
    "    # create flow arrays\n",
    "    all_dest = np.delete(all_dest,np.where(all_dest == O))\n",
    "    D_array = np.array([D]*len(all_dest), dtype=object)\n",
    "    \n",
    "    # Create all destination flows except origin\n",
    "    x1 = pd.DataFrame({'D': D_array, 'dests':all_dest})\n",
    "    \n",
    "    # merge with the distances and masses\n",
    "    x2 = x1.merge(distances_df, how='left', left_on=['D','dests'], right_on=['origin_ID','dest_ID'])\n",
    "    x3 = x2.merge(dest_masses_df, how='left', left_on=['dest_ID'], right_on=['ID'])\n",
    "    \n",
    "    # Delete the flow to origin\n",
    "    x3 = x3[~x3.dests.isin(list(O))] \n",
    "    \n",
    "    # calculate the accessibility\n",
    "    x3['A'] = x3['weight']*x3['mass']\n",
    "    A = x3['A'].sum()\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "korean-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. AFOE = Accessibility of flow taking only existing destinations\n",
    "\n",
    "def AFOE(distances_df, dest_masses_df, flow_df, row_index): # AFEF\n",
    "    # rename teh columns so we can call them \n",
    "    distances_df = distances_df.rename(columns = {distances_df.columns[0]:'origin_ID', distances_df.columns[1]:'dest_ID', distances_df.columns[2]:'weight'})\n",
    "    dest_masses_df = dest_masses_df.rename(columns = {dest_masses_df.columns[0]:'ID', dest_masses_df.columns[1]:'mass'})\n",
    "    flow_df = flow_df.rename(columns = {flow_df.columns[0]:'origin_ID', flow_df.columns[1]:'dest_ID'})\n",
    "    \n",
    "    # define the variables\n",
    "    D = flow_df['dest_ID'][row_index]\n",
    "    O = flow_df['origin_ID'][row_index]\n",
    "    all_dest = flow_df.loc[flow_df['origin_ID']==O,:]['dest_ID'].unique()\n",
    "    \n",
    "    # create flow arrays\n",
    "    all_dest = np.delete(all_dest,np.where(all_dest == O))\n",
    "    D_array = np.array([D]*len(all_dest), dtype=object)\n",
    "    \n",
    "    # Create all destination flows except origin\n",
    "    x1 = pd.DataFrame({'D': D_array, 'dests':all_dest})\n",
    "    \n",
    "    # merge with the distances and masses\n",
    "    x2 = x1.merge(distances_df, how='left', left_on=['D','dests'], right_on=['origin_ID','dest_ID'])\n",
    "    x3 = x2.merge(dest_masses_df, how='left', left_on=['dest_ID'], right_on=['ID'])\n",
    "    \n",
    "    # Delete the flow to origin\n",
    "    x3 = x3[~x3.dests.isin(list(O))] \n",
    "    \n",
    "    # calculate the accessibility\n",
    "    x3['A'] = x3['weight']*x3['mass']\n",
    "    A = x3['A'].sum()\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "healthy-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. AFED = Accessibility of flow taking existing destinations\n",
    "\n",
    "def AFED(flow_df, row_index): # AFAPF\n",
    "    \n",
    "    # rename teh columns so we can call them \n",
    "    flow_df = flow_df.rename(columns = {flow_df.columns[0]:'origin_ID', \n",
    "                                            flow_df.columns[1]:'dest_ID', \n",
    "                                            flow_df.columns[2]:'dist', \n",
    "                                            flow_df.columns[3]:'weight', \n",
    "                                            flow_df.columns[4]:'dest_mass'})\n",
    "    # define O and D for each row the variables\n",
    "    D = flow_df['dest_ID'][row_index]\n",
    "    O = flow_df['origin_ID'][row_index]\n",
    "    \n",
    "    # get the list of possible destinations\n",
    "    all_dest = (flow_df.query('origin_ID == @O')\n",
    "                .query('weight > 0')\n",
    "                ['dest_ID']\n",
    "                .unique()\n",
    "               )    \n",
    "    \n",
    "    # Create all destination flows \n",
    "    x1 = pd.DataFrame({'D': np.array([D]*len(all_dest), dtype=object), \n",
    "                       'dests':all_dest}).merge(flow_df, how='left', left_on=['D','dests'], right_on=['origin_ID','dest_ID'])\n",
    "    \n",
    "    # merge with the distances and masses \n",
    "    \n",
    "    # Delete the flow to origin\n",
    "    x1 = x1[~x1.dests.isin(list(O))]    \n",
    "\n",
    "    # calculate the accessibility\n",
    "    A = (x1['dist']*x1['dest_mass']).sum()\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-essex",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sunset-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyproj import CRS\n",
    "import itertools\n",
    "from geopy.distance import geodesic, great_circle\n",
    "from timeit import default_timer as timer\n",
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "neither-still",
   "metadata": {},
   "source": [
    "# define coordinates if you need them\n",
    "wgs84 = CRS(4326)\n",
    "bng = CRS(27700)\n",
    "print(wgs84)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-treatment",
   "metadata": {},
   "source": [
    "## Define the test data\n",
    "\n",
    "### Load sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "angry-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 855 entries, 0 to 854\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   ID_code   855 non-null    object  \n",
      " 1   X         855 non-null    float64 \n",
      " 2   Y         855 non-null    float64 \n",
      " 3   geometry  855 non-null    geometry\n",
      "dtypes: float64(2), geometry(1), object(1)\n",
      "memory usage: 26.8+ KB\n"
     ]
    }
   ],
   "source": [
    "pois = gpd.read_file(\"./points.geojson\")\n",
    "\n",
    "\n",
    "pois.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bacterial-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tk18583\\Anaconda3\\envs\\CD\\lib\\site-packages\\geopandas\\geodataframe.py:1322: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super(GeoDataFrame, self).__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# strip\n",
    "pois_all = pois.iloc[:,[0,3]]\n",
    "\n",
    "# Add random masses\n",
    "pois_all['mass'] = pd.Series( np.random.randint(0,1500, size=len(pois_all))\n",
    "                            )\n",
    "# create stripped column of coordinates \n",
    "pois_all['xy'] = pois_all.geometry.apply(lambda x: [x.y, x.x])\n",
    "\n",
    "# get all unique combinations of all the origins and destinations\n",
    "flow_all = pd.DataFrame( list( itertools.product( pois_all['ID_code'].unique(),pois_all['ID_code'].unique())\n",
    "                             )\n",
    "                       ).rename(columns = {0:'origin',\n",
    "                                        1:'destination'})\n",
    "\n",
    "# joining the xy to flows and create distances\n",
    "distances_all = flow_all.merge(pois_all.loc[:,['ID_code','xy']], how = 'left', left_on = 'origin', right_on = 'ID_code' \n",
    "                        ).merge(pois_all.loc[:,['ID_code','xy']], how = 'left', left_on = 'destination', right_on = 'ID_code'\n",
    "                               )\n",
    "\n",
    "\n",
    "# calculate distances\n",
    "distances_all['great_circle_dist'] = distances_all.apply(lambda x: great_circle(x.xy_x, x.xy_y).km, axis=1)\n",
    "distances_all = distances_all.loc[:,['origin','destination','great_circle_dist']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "compressed-fence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A91120</td>\n",
       "      <td>A91120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A91120</td>\n",
       "      <td>A99931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A91120</td>\n",
       "      <td>A99986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A91120</td>\n",
       "      <td>L81002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91120</td>\n",
       "      <td>L81004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin destination\n",
       "0  A91120      A91120\n",
       "1  A91120      A99931\n",
       "2  A91120      A99986\n",
       "3  A91120      L81002\n",
       "4  A91120      L81004"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "treated-member",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>great_circle_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A91120</td>\n",
       "      <td>A91120</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A91120</td>\n",
       "      <td>A99931</td>\n",
       "      <td>5.490762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A91120</td>\n",
       "      <td>A99986</td>\n",
       "      <td>2.598773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A91120</td>\n",
       "      <td>L81002</td>\n",
       "      <td>30.232818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91120</td>\n",
       "      <td>L81004</td>\n",
       "      <td>14.588663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin destination  great_circle_dist\n",
       "0  A91120      A91120           0.000000\n",
       "1  A91120      A99931           5.490762\n",
       "2  A91120      A99986           2.598773\n",
       "3  A91120      L81002          30.232818\n",
       "4  A91120      L81004          14.588663"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "comfortable-concentrate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>geometry</th>\n",
       "      <th>mass</th>\n",
       "      <th>xy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A91120</td>\n",
       "      <td>POINT (-2.55906 51.50283)</td>\n",
       "      <td>1274</td>\n",
       "      <td>[51.502830094350216, -2.55906333659297]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A99931</td>\n",
       "      <td>POINT (-2.59614 51.45918)</td>\n",
       "      <td>714</td>\n",
       "      <td>[51.4591818706117, -2.596140188956506]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A99986</td>\n",
       "      <td>POINT (-2.53883 51.48314)</td>\n",
       "      <td>503</td>\n",
       "      <td>[51.48314321496156, -2.538833345365197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L81002</td>\n",
       "      <td>POINT (-2.93035 51.36021)</td>\n",
       "      <td>536</td>\n",
       "      <td>[51.360206696542896, -2.930352226593651]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L81004</td>\n",
       "      <td>POINT (-2.76732 51.48281)</td>\n",
       "      <td>546</td>\n",
       "      <td>[51.482805431236095, -2.76731748987437]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code                   geometry  mass  \\\n",
       "0  A91120  POINT (-2.55906 51.50283)  1274   \n",
       "1  A99931  POINT (-2.59614 51.45918)   714   \n",
       "2  A99986  POINT (-2.53883 51.48314)   503   \n",
       "3  L81002  POINT (-2.93035 51.36021)   536   \n",
       "4  L81004  POINT (-2.76732 51.48281)   546   \n",
       "\n",
       "                                         xy  \n",
       "0   [51.502830094350216, -2.55906333659297]  \n",
       "1    [51.4591818706117, -2.596140188956506]  \n",
       "2   [51.48314321496156, -2.538833345365197]  \n",
       "3  [51.360206696542896, -2.930352226593651]  \n",
       "4   [51.482805431236095, -2.76731748987437]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pois_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-coalition",
   "metadata": {},
   "source": [
    "From this data, we create 6 subsets of data for different number of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "swedish-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list points\n",
    "list5 = list(pois_all['ID_code'][0:6])\n",
    "list10 = list(pois_all['ID_code'][0:11])\n",
    "list20 = list(pois_all['ID_code'][0:21])\n",
    "list40 = list(pois_all['ID_code'][0:41])\n",
    "list80 = list(pois_all['ID_code'][0:81])\n",
    "list160 = list(pois_all['ID_code'][0:161])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "affecting-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different number of points\n",
    "pois_all_s = pd.DataFrame(pois_all.loc[:,['ID_code','mass']])\n",
    "pois5 = pois_all_s[pois_all_s['ID_code'].isin(list5)]\n",
    "pois10 = pois_all_s[pois_all_s['ID_code'].isin(list10)]\n",
    "pois20 = pois_all_s[pois_all_s['ID_code'].isin(list20)]\n",
    "pois40 = pois_all_s[pois_all_s['ID_code'].isin(list40)]\n",
    "pois80 = pois_all_s[pois_all_s['ID_code'].isin(list80)]\n",
    "pois160 = pois_all_s[pois_all_s['ID_code'].isin(list160)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "excess-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow5 = flow_all[flow_all['origin'].isin(list5) & flow_all['destination'].isin(list5)].reset_index(drop=True)\n",
    "flow10 = flow_all[flow_all['origin'].isin(list10) & flow_all['destination'].isin(list10)].reset_index(drop=True)\n",
    "flow20 = flow_all[flow_all['origin'].isin(list20) & flow_all['destination'].isin(list20)].reset_index(drop=True)\n",
    "flow40 = flow_all[flow_all['origin'].isin(list40) & flow_all['destination'].isin(list40)].reset_index(drop=True)\n",
    "flow80 = flow_all[flow_all['origin'].isin(list80) & flow_all['destination'].isin(list80)].reset_index(drop=True)\n",
    "flow160 = flow_all[flow_all['origin'].isin(list160) & flow_all['destination'].isin(list160)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "growing-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances5 = distances_all[distances_all['origin'].isin(list5) & distances_all['destination'].isin(list5)].reset_index(drop=True)\n",
    "distances10 = distances_all[distances_all['origin'].isin(list10) & distances_all['destination'].isin(list10)].reset_index(drop=True)\n",
    "distances20 = distances_all[distances_all['origin'].isin(list20) & distances_all['destination'].isin(list20)].reset_index(drop=True)\n",
    "distances40 = distances_all[distances_all['origin'].isin(list40) & distances_all['destination'].isin(list40)].reset_index(drop=True)\n",
    "distances80 = distances_all[distances_all['origin'].isin(list80) & distances_all['destination'].isin(list80)].reset_index(drop=True)\n",
    "distances160 = distances_all[distances_all['origin'].isin(list160) & distances_all['destination'].isin(list160)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-minority",
   "metadata": {},
   "source": [
    "**Now what if some flows just does not exist**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "voluntary-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_ommited = [1,4,5,9,13,15,17,26,27,28,34]\n",
    "\n",
    "flow5_ommited = flow5.drop(flow5.index[li_ommited]).reset_index(drop=True)\n",
    "flow10_ommited = flow10.drop(flow10.index[li_ommited]).reset_index(drop=True)\n",
    "flow20_ommited = flow20.drop(flow20.index[li_ommited]).reset_index(drop=True)\n",
    "flow40_ommited = flow40.drop(flow40.index[li_ommited]).reset_index(drop=True)\n",
    "flow80_ommited = flow80.drop(flow80.index[li_ommited]).reset_index(drop=True)\n",
    "flow160_ommited = flow160.drop(flow160.index[li_ommited]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-supply",
   "metadata": {},
   "source": [
    "**Now get this all together for the last function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "wound-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the points and distances\n",
    "flow_integrated = distances_all.merge(pois_all_s, how = 'left', left_on=['destination'], right_on=['ID_code'])\n",
    "\n",
    "#generate some weights\n",
    "flow_integrated['weight'] = pd.Series( np.random.randint(-50,1500, size=len(flow_integrated)) # here - and 0 represent flows that does not exist\n",
    "                                     )\n",
    "# reorder\n",
    "flow_integrated = flow_integrated.loc[:,['origin','destination','great_circle_dist','weight','mass']]\n",
    "\n",
    "# build short datasets\n",
    "flow5_integrated = flow_integrated[flow_integrated['origin'].isin(list5) & flow_integrated['destination'].isin(list5)].reset_index(drop=True)\n",
    "flow10_integrated = flow_integrated[flow_integrated['origin'].isin(list10) & flow_integrated['destination'].isin(list10)].reset_index(drop=True)\n",
    "flow20_integrated = flow_integrated[flow_integrated['origin'].isin(list20) & flow_integrated['destination'].isin(list20)].reset_index(drop=True)\n",
    "flow40_integrated = flow_integrated[flow_integrated['origin'].isin(list40) & flow_integrated['destination'].isin(list40)].reset_index(drop=True)\n",
    "flow80_integrated = flow_integrated[flow_integrated['origin'].isin(list80) & flow_integrated['destination'].isin(list80)].reset_index(drop=True)\n",
    "flow160_integrated = flow_integrated[flow_integrated['origin'].isin(list160) & flow_integrated['destination'].isin(list160)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fundamental-minority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>destination</th>\n",
       "      <th>great_circle_dist</th>\n",
       "      <th>weight</th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A91120</td>\n",
       "      <td>A91120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-37</td>\n",
       "      <td>1274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A91120</td>\n",
       "      <td>A99931</td>\n",
       "      <td>5.490762</td>\n",
       "      <td>853</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A91120</td>\n",
       "      <td>A99986</td>\n",
       "      <td>2.598773</td>\n",
       "      <td>872</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A91120</td>\n",
       "      <td>L81002</td>\n",
       "      <td>30.232818</td>\n",
       "      <td>888</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A91120</td>\n",
       "      <td>L81004</td>\n",
       "      <td>14.588663</td>\n",
       "      <td>817</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   origin destination  great_circle_dist  weight  mass\n",
       "0  A91120      A91120           0.000000     -37  1274\n",
       "1  A91120      A99931           5.490762     853   714\n",
       "2  A91120      A99986           2.598773     872   503\n",
       "3  A91120      L81002          30.232818     888   536\n",
       "4  A91120      L81004          14.588663     817   546"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_integrated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-supply",
   "metadata": {},
   "source": [
    "## Apply the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "exterior-reserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 28291.653752719987\n",
      "time: 0.009097800008021295\n"
     ]
    }
   ],
   "source": [
    "# 1 row of data\n",
    "start = timer()\n",
    "\n",
    "print('result: '+str(AFAP(distances_df=distances5, dest_masses_df = pois5, flow_df=flow5, row_index=1)))\n",
    "\n",
    "end = timer()\n",
    "print('time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "adapted-initial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39646.87373850662, 28291.653752719987, 36643.975562554166, 69541.00185242042, 42129.87623628721, 30107.476149318078, 35726.46996848799, 35286.884009027686, 36541.44035498807, 89736.30775672542, 52044.99647355058, 38996.00346729661, 38339.690903787865, 32882.22554847106, 39954.81240436674, 92768.87827386541, 52757.49347263157, 38756.314969528656, 23442.083242567915, 21533.075707741198, 23663.040376669924, 108057.61209836442, 51223.34257726144, 29115.49908853596, 31681.463839276348, 28656.24456634767, 31316.138049346235, 98388.02331208192, 60715.83266782445, 34310.8387900778, 29397.78699990634, 29784.336460830847, 31654.655273908567, 81796.2371983645, 44707.62191156702, 42821.533116189275]\n",
      "time: 0.2350453999970341\n"
     ]
    }
   ],
   "source": [
    "# for 05 dataset function 1\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow5.index:\n",
    "    A = AFAP(distances_df=distances5, dest_masses_df = pois5, flow_df=flow5, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "print(A_ij)\n",
    "print('time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "precious-myanmar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17511.973330657445, 16291.77202769682, 15288.733824499002, 19521.679472549287, 21533.075707741198, 20249.668327291256, 42552.50638298757, 25289.96943964329, 7965.409899230267, 11949.511196833084, 18585.956431537248, 23442.083242567915, 21533.075707741198, 23663.040376669924, 108057.61209836442, 51223.34257726144, 29115.49908853596, 14169.490508618901, 12497.777804504545, 16539.586615763867, 21432.377100676073, 23153.697018150826, 23015.98091888806, 72126.648412082, 34310.8387900778]\n",
      "time: 0.18158589999075048\n"
     ]
    }
   ],
   "source": [
    "# for 05 dataset function 2\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow5_ommited.index:\n",
    "    A = AFOE(distances_df=distances5, dest_masses_df = pois5, flow_df=flow5_ommited, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "print(A_ij)\n",
    "print('time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "photographic-printer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39646.87373850662, 28291.653752719987, 36643.975562554166, 69541.00185242042, 42129.87623628721, 30107.476149318078, 39646.87373850662, 35286.884009027686, 39954.81240436674, 108057.61209836442, 60715.83266782445, 42821.533116189275, 35726.46996848799, 35286.884009027686, 36541.44035498807, 89736.30775672542, 52044.99647355058, 38996.00346729661, 39646.87373850662, 35286.884009027686, 39954.81240436674, 108057.61209836442, 60715.83266782445, 42821.533116189275, 31681.463839276348, 28656.24456634767, 31316.138049346235, 98388.02331208192, 60715.83266782445, 34310.8387900778, 39646.87373850662, 35286.884009027686, 39954.81240436674, 108057.61209836442, 60715.83266782445, 42821.533116189275]\n",
      "time: 0.2819428000075277\n"
     ]
    }
   ],
   "source": [
    "# for 05 dataset function 3\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow5_integrated.index:\n",
    "    A = AFED(flow_df=flow5_integrated, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "print(A_ij)\n",
    "print('time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "perfect-evanescence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 50.92319200000202\n"
     ]
    }
   ],
   "source": [
    "# for 80 dataset function 2\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow80_ommited.index:\n",
    "    A = AFOE(distances_df=distances80, dest_masses_df = pois80, flow_df=flow80_ommited, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "print('time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-missouri",
   "metadata": {},
   "source": [
    "**From this it looks like the last function is actually the slowest**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-opportunity",
   "metadata": {},
   "source": [
    "## Lets have a look at how they perform for different lenght data\n",
    "\n",
    "I honestly did not know how to turn this into function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "auburn-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 05 dataset function 1\n",
    "list_AFAP = []\n",
    "\n",
    "# 05\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow5.index:\n",
    "    A = AFAP(distances_df=distances5, dest_masses_df = pois5, flow_df=flow5, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFAP.append(t)\n",
    "\n",
    "# 010\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow10.index:\n",
    "    A = AFAP(distances_df=distances10, dest_masses_df = pois10, flow_df=flow10, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFAP.append(t)\n",
    "\n",
    "# 020\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow20.index:\n",
    "    A = AFAP(distances_df=distances20, dest_masses_df = pois20, flow_df=flow20, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFAP.append(t)\n",
    "\n",
    "# 040\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow40.index:\n",
    "    A = AFAP(distances_df=distances40, dest_masses_df = pois40, flow_df=flow40, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFAP.append(t)\n",
    "\n",
    "# 080\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow80.index:\n",
    "    A = AFAP(distances_df=distances80, dest_masses_df = pois80, flow_df=flow80, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFAP.append(t)\n",
    "\n",
    "# 0160\n",
    "start = timer()\n",
    "\n",
    "A_ij = []\n",
    "for idx in flow160.index:\n",
    "    A = AFAP(distances_df=distances160, dest_masses_df = pois160, flow_df=flow160, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFAP.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "pregnant-courage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22016539999458473,\n",
       " 0.6652746999898227,\n",
       " 2.5453638000035426,\n",
       " 10.011837099998957,\n",
       " 44.60239569999976,\n",
       " 297.26800330000697]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_AFAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "conditional-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 05 dataset function 2\n",
    "list_AFOE = []\n",
    "\n",
    "# 05\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow5_ommited.index:\n",
    "    A = AFOE(distances_df=distances5, dest_masses_df = pois5, flow_df=flow5_ommited, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFOE.append(t)\n",
    "\n",
    "# 10\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow10_ommited.index:\n",
    "    A = AFOE(distances_df=distances10, dest_masses_df = pois10, flow_df=flow10_ommited, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFOE.append(t)\n",
    "\n",
    "# 20\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow20_ommited.index:\n",
    "    A = AFOE(distances_df=distances20, dest_masses_df = pois20, flow_df=flow20_ommited, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFOE.append(t)\n",
    "\n",
    "# 40\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow40_ommited.index:\n",
    "    A = AFOE(distances_df=distances40, dest_masses_df = pois40, flow_df=flow40_ommited, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFOE.append(t)\n",
    "\n",
    "# 80\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow80_ommited.index:\n",
    "    A = AFOE(distances_df=distances80, dest_masses_df = pois80, flow_df=flow80_ommited, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFOE.append(t)\n",
    "\n",
    "# 160\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow160_ommited.index:\n",
    "    A = AFOE(distances_df=distances160, dest_masses_df = pois160, flow_df=flow160_ommited, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFOE.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "banned-maine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1797835000033956,\n",
       " 0.740869000001112,\n",
       " 3.0739694999938365,\n",
       " 12.089085700004944,\n",
       " 52.620727999994415,\n",
       " 329.4732937999943]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_AFOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 05 dataset function 3\n",
    "list_AFED = []\n",
    "\n",
    "# 5\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow5_integrated.index:\n",
    "    A = AFED(flow_df=flow5_integrated, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFED.append(t)\n",
    "\n",
    "# 10\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow10_integrated.index:\n",
    "    A = AFED(flow_df=flow10_integrated, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFED.append(t)\n",
    "\n",
    "# 20\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow20_integrated.index:\n",
    "    A = AFED(flow_df=flow20_integrated, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFED.append(t)\n",
    "\n",
    "# 40\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow40_integrated.index:\n",
    "    A = AFED(flow_df=flow40_integrated, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFED.append(t)\n",
    "\n",
    "# 80\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow80_integrated.index:\n",
    "    A = AFED(flow_df=flow80_integrated, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFED.append(t)\n",
    "\n",
    "# 160\n",
    "start = timer()\n",
    "A_ij = []\n",
    "for idx in flow160_integrated.index:\n",
    "    A = AFED(flow_df=flow160_integrated, row_index=idx)\n",
    "    A_ij.append(A)\n",
    "end = timer()\n",
    "t = (end - start)\n",
    "list_AFED.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-pasta",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_AFED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.DataFrame({'AFAP': pd.Series(list_AFAP),\n",
    "                     'AFOE': pd.Series(list_AFOE),\n",
    "                     'AFED': pd.Series(list_AFED)})\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(len(flow5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "(times.iloc[:,0:3]/60).plot()\n",
    "plt.xlabel(\"Number of observations\")\n",
    "plt.ylabel(\"Minutes\")\n",
    "plt.xticks(times.index, (str(len(flow5)), str(len(flow10)), str(len(flow20)), str(len(flow40)),str(len(flow80)), str(len(flow160))));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-biology",
   "metadata": {},
   "source": [
    "Time per one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_n = [len(flow5), len(flow10), len(flow20), len(flow40), len(flow80), len(flow160)]\n",
    "times['AFAP_1'] = times['AFAP']/pd.Series(li_n)\n",
    "times['AFOE_1'] = times['AFOE']/pd.Series(li_n)\n",
    "times['AFED_1'] = times['AFED']/pd.Series(li_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "times.iloc[:,3:6].plot()\n",
    "plt.xlabel(\"Number of observations\")\n",
    "plt.ylabel(\"Seconds\")\n",
    "plt.xticks(times.index, (str(len(flow5)), str(len(flow10)), str(len(flow20)), str(len(flow40)),str(len(flow80)), str(len(flow160))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flow_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-least",
   "metadata": {},
   "source": [
    "### How long will it take to do whole dataset?\n",
    "\n",
    "Ok it will take something between and 0.5 to 2.5 hours to compute a dataset...probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "times['observations'] = pd.Series(li_n)\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(times['AFED']).values.reshape(-1,1)\n",
    "x = np.log(times['observations']).values.reshape(-1,1)\n",
    "model = LinearRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "occasional-place",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731025"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flow_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "infinite-exclusive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observations</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.190754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.697906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.0</td>\n",
       "      <td>2.784519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1681.0</td>\n",
       "      <td>11.655805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6561.0</td>\n",
       "      <td>50.041045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25921.0</td>\n",
       "      <td>217.650303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>731025.0</td>\n",
       "      <td>7753.882324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   observations    predicted\n",
       "0          36.0     0.190754\n",
       "1         121.0     0.697906\n",
       "2         441.0     2.784519\n",
       "3        1681.0    11.655805\n",
       "4        6561.0    50.041045\n",
       "5       25921.0   217.650303\n",
       "6      731025.0  7753.882324"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = times.loc[:,['observations']]\n",
    "pred.loc[6,['observations']] = len(flow_all)\n",
    "\n",
    "pred['predicted'] = np.exp(model.predict(np.log(pred).values.reshape(-1,1)).flatten())\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "subsequent-planner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observations</th>\n",
       "      <th>predicted</th>\n",
       "      <th>min</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.190754</td>\n",
       "      <td>0.003179</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.697906</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.0</td>\n",
       "      <td>2.784519</td>\n",
       "      <td>0.046409</td>\n",
       "      <td>0.000773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1681.0</td>\n",
       "      <td>11.655805</td>\n",
       "      <td>0.194263</td>\n",
       "      <td>0.003238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6561.0</td>\n",
       "      <td>50.041045</td>\n",
       "      <td>0.834017</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25921.0</td>\n",
       "      <td>217.650303</td>\n",
       "      <td>3.627505</td>\n",
       "      <td>0.060458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>731025.0</td>\n",
       "      <td>7753.882324</td>\n",
       "      <td>129.231372</td>\n",
       "      <td>2.153856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   observations    predicted         min         h\n",
       "0          36.0     0.190754    0.003179  0.000053\n",
       "1         121.0     0.697906    0.011632  0.000194\n",
       "2         441.0     2.784519    0.046409  0.000773\n",
       "3        1681.0    11.655805    0.194263  0.003238\n",
       "4        6561.0    50.041045    0.834017  0.013900\n",
       "5       25921.0   217.650303    3.627505  0.060458\n",
       "6      731025.0  7753.882324  129.231372  2.153856"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['min'] = pred['predicted']/60\n",
    "pred['h'] = pred['min']/60\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "connected-surrey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.991485458501312"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is probably worng, it could as well be 16 hours\n",
    "r1 = 0.006646-0.005952\n",
    "r2 = 0.007023-0.006646\n",
    "r3 = 0.009741-0.007023\n",
    "\n",
    "f = 731025.0/25921.0\n",
    "i_d = f*r3\n",
    "pu = 0.007023+i_d\n",
    "((pu*len(flow_all))/60)/60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-montgomery",
   "metadata": {},
   "source": [
    "What about the migration data? there is 121104 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "streaming-language",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observations</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.190754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.697906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.0</td>\n",
       "      <td>2.784519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1681.0</td>\n",
       "      <td>11.655805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6561.0</td>\n",
       "      <td>50.041045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25921.0</td>\n",
       "      <td>217.650303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>731025.0</td>\n",
       "      <td>7753.882324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>121104.0</td>\n",
       "      <td>1132.694871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   observations    predicted\n",
       "0          36.0     0.190754\n",
       "1         121.0     0.697906\n",
       "2         441.0     2.784519\n",
       "3        1681.0    11.655805\n",
       "4        6561.0    50.041045\n",
       "5       25921.0   217.650303\n",
       "6      731025.0  7753.882324\n",
       "7      121104.0  1132.694871"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predm = pred.loc[:,['observations']]\n",
    "predm.loc[7,['observations']] = 121104\n",
    "predm['predicted'] = np.exp(model.predict(np.log(predm).values.reshape(-1,1)).flatten())\n",
    "predm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "given-cleanup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observations</th>\n",
       "      <th>predicted</th>\n",
       "      <th>min</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.190233</td>\n",
       "      <td>0.003171</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.0</td>\n",
       "      <td>0.698249</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.0</td>\n",
       "      <td>2.795497</td>\n",
       "      <td>0.046592</td>\n",
       "      <td>0.000777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1681.0</td>\n",
       "      <td>11.743519</td>\n",
       "      <td>0.195725</td>\n",
       "      <td>0.003262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6561.0</td>\n",
       "      <td>50.600749</td>\n",
       "      <td>0.843346</td>\n",
       "      <td>0.014056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25921.0</td>\n",
       "      <td>220.891228</td>\n",
       "      <td>3.681520</td>\n",
       "      <td>0.061359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>731025.0</td>\n",
       "      <td>7939.619233</td>\n",
       "      <td>132.326987</td>\n",
       "      <td>2.205450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>121104.0</td>\n",
       "      <td>1154.289236</td>\n",
       "      <td>19.238154</td>\n",
       "      <td>0.320636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   observations    predicted         min         h\n",
       "0          36.0     0.190233    0.003171  0.000053\n",
       "1         121.0     0.698249    0.011637  0.000194\n",
       "2         441.0     2.795497    0.046592  0.000777\n",
       "3        1681.0    11.743519    0.195725  0.003262\n",
       "4        6561.0    50.600749    0.843346  0.014056\n",
       "5       25921.0   220.891228    3.681520  0.061359\n",
       "6      731025.0  7939.619233  132.326987  2.205450\n",
       "7      121104.0  1154.289236   19.238154  0.320636"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predm['min'] = predm['predicted']/60\n",
    "predm['h'] = predm['min']/60\n",
    "predm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-serbia",
   "metadata": {},
   "source": [
    "Ok it will take something between and 0.5 to 2.5 hours to compute a dataset...great"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-england",
   "metadata": {},
   "source": [
    "## Can we speed it up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "interested-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "unavailable-occasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "responsible-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. AFED = Alter\n",
    "\n",
    "def A_M(row_index, flow_df = flow40_integrated): \n",
    "    \n",
    "    # rename teh columns so we can call them \n",
    "    flow_df = flow_df.rename(columns = {flow_df.columns[0]:'origin_ID', \n",
    "                                            flow_df.columns[1]:'dest_ID', \n",
    "                                            flow_df.columns[2]:'dist', \n",
    "                                            flow_df.columns[3]:'weight', \n",
    "                                            flow_df.columns[4]:'dest_mass'})\n",
    "    # define O and D for each row the variables\n",
    "    D = flow_df['dest_ID'][row_index]\n",
    "    O = flow_df['origin_ID'][row_index]\n",
    "    \n",
    "    # get the list of possible destinations\n",
    "    all_dest = (flow_df.query('origin_ID == @O')\n",
    "                .query('weight > 0')\n",
    "                ['dest_ID']\n",
    "                .unique()\n",
    "               )    \n",
    "    \n",
    "    # Create all destination flows \n",
    "    x1 = pd.DataFrame({'D': np.array([D]*len(all_dest), dtype=object), \n",
    "                       'dests':all_dest}).merge(flow_df, how='left', left_on=['D','dests'], right_on=['origin_ID','dest_ID'])\n",
    "    \n",
    "    # merge with the distances and masses \n",
    "    \n",
    "    # calculate the accessibility\n",
    "    A = (x1['weight']*x1['dest_mass']).sum()\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-breast",
   "metadata": {},
   "source": [
    "cups = 4\n",
    "\n",
    "\n",
    "with Pool(cups) as pool:\n",
    "    accessibilities_2 = pool.map(A_M, flow40_integrated.index)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "frequent-reception",
   "metadata": {},
   "source": [
    "n_cups = 4\n",
    "\n",
    "if (__name__ == '__main__'):\n",
    "    pool = Pool(n_cups)\n",
    "    a2 = pool.map(A_M, flow40_integrated.index)\n",
    "    print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-longitude",
   "metadata": {},
   "source": [
    "def main():\n",
    "    pool = Pool(processes=3)  # set the processes max number 3\n",
    "    result = pool.map(A_M, flow40_integrated.index)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print(result)\n",
    "    print('end')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-slope",
   "metadata": {},
   "source": [
    "**This is not working for some reason, it runs and never ends**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-lotus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
